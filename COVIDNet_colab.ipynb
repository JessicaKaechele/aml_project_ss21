{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"COVIDNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM94UMO6ZIKAuiVGMKlsvVH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jMu4WCG3zmCa","executionInfo":{"status":"ok","timestamp":1633076015644,"user_tz":-120,"elapsed":23001,"user":{"displayName":"nameohne","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13436963316072193918"}},"outputId":"c88931b4-c955-4cb8-b563-125c34291220"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZCim4u744ux","executionInfo":{"status":"ok","timestamp":1633076020044,"user_tz":-120,"elapsed":4417,"user":{"displayName":"nameohne","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13436963316072193918"}},"outputId":"c5bc38e2-1ed1-4ba1-bbb7-b251bd89b707"},"source":["!pip install -r /content/drive/MyDrive/covidnet/requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting absl-py==0.10.0\n","  Downloading absl_py-0.10.0-py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 12.8 MB/s \n","\u001b[?25hCollecting aiohttp==3.6.2\n","  Downloading aiohttp-3.6.2-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 58.7 MB/s \n","\u001b[?25hCollecting anyio==2.1.0\n","  Downloading anyio-2.1.0-py3-none-any.whl (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.8 MB/s \n","\u001b[?25hCollecting argon2-cffi==20.1.0\n","  Downloading argon2_cffi-20.1.0-cp35-abi3-manylinux1_x86_64.whl (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/covidnet/requirements.txt (line 5)) (0.8.1)\n","Collecting async-generator==1.10\n","  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n","Collecting async-timeout==3.0.1\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Collecting attrs==20.2.0\n","  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 6.7 MB/s \n","\u001b[?25hCollecting Babel==2.9.0\n","  Downloading Babel-2.9.0-py2.py3-none-any.whl (8.8 MB)\n","\u001b[K     |████████████████████████████████| 8.8 MB 61.6 MB/s \n","\u001b[?25hRequirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/covidnet/requirements.txt (line 10)) (0.2.0)\n","Collecting bleach==3.2.1\n","  Downloading bleach-3.2.1-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 68.0 MB/s \n","\u001b[?25hRequirement already satisfied: cached-property==1.5.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/covidnet/requirements.txt (line 12)) (1.5.2)\n","Collecting cachetools==4.1.1\n","  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n","Collecting certifi==2020.6.20\n","  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 69.3 MB/s \n","\u001b[?25hCollecting cffi==1.14.3\n","  Downloading cffi-1.14.3-cp37-cp37m-manylinux1_x86_64.whl (401 kB)\n","\u001b[K     |████████████████████████████████| 401 kB 58.9 MB/s \n","\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/covidnet/requirements.txt (line 16)) (3.0.4)\n","Collecting contextvars==2.4\n","  Downloading contextvars-2.4.tar.gz (9.6 kB)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/covidnet/requirements.txt (line 18)) (0.10.0)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement dataclasses==0.8 (from versions: 0.1, 0.2, 0.3, 0.4, 0.5, 0.6)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for dataclasses==0.8\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxfAeOxFrxBb","executionInfo":{"status":"ok","timestamp":1633076022826,"user_tz":-120,"elapsed":2791,"user":{"displayName":"nameohne","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13436963316072193918"}},"outputId":"dd38e734-9416-468b-fe45-1855faef76b9"},"source":["from __future__ import print_function\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","from tensorflow import keras\n","\n","import numpy as np\n","import os, argparse, pathlib\n","import cv2\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.metrics import confusion_matrix"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}]},{"cell_type":"code","metadata":{"id":"YiN9XFxIrmbR"},"source":["# original code from: https://github.com/lindawangg/COVID-Net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVXjAfNqr-7H"},"source":["def crop_top(img, percent=0.15):\n","    offset = int(img.shape[0] * percent)\n","    return img[offset:]\n","\n","def central_crop(img):\n","    size = min(img.shape[0], img.shape[1])\n","    offset_h = int((img.shape[0] - size) / 2)\n","    offset_w = int((img.shape[1] - size) / 2)\n","    return img[offset_h:offset_h + size, offset_w:offset_w + size]\n","\n","def process_image_file(filepath, top_percent, size):\n","    img = cv2.imread(filepath)\n","    img = crop_top(img, percent=top_percent)\n","    img = central_crop(img)\n","    img = cv2.resize(img, (size, size))\n","    return img\n","\n","def random_ratio_resize(img, prob=0.3, delta=0.1):\n","    if np.random.rand() >= prob:\n","        return img\n","    ratio = img.shape[0] / img.shape[1]\n","    ratio = np.random.uniform(max(ratio - delta, 0.01), ratio + delta)\n","\n","    if ratio * img.shape[1] <= img.shape[1]:\n","        size = (int(img.shape[1] * ratio), img.shape[1])\n","    else:\n","        size = (img.shape[0], int(img.shape[0] / ratio))\n","\n","    dh = img.shape[0] - size[1]\n","    top, bot = dh // 2, dh - dh // 2\n","    dw = img.shape[1] - size[0]\n","    left, right = dw // 2, dw - dw // 2\n","\n","    if size[0] > 480 or size[1] > 480:\n","        print(img.shape, size, ratio)\n","\n","    img = cv2.resize(img, size)\n","    img = cv2.copyMakeBorder(img, top, bot, left, right, cv2.BORDER_CONSTANT,\n","                             (0, 0, 0))\n","\n","    if img.shape[0] != 480 or img.shape[1] != 480:\n","        raise ValueError(img.shape, size)\n","    return img\n","\n","# _augmentation_transform = ImageDataGenerator(\n","#     featurewise_center=False,\n","#     featurewise_std_normalization=False,\n","#     rotation_range=10,\n","#     width_shift_range=0.1,\n","#     height_shift_range=0.1,\n","#     horizontal_flip=True,\n","#     brightness_range=(0.9, 1.1),\n","#     zoom_range=(0.85, 1.15),\n","#     fill_mode='constant',\n","#     cval=0.,\n","# )\n","\n","_augmentation_transform = None\n","\n","def get_augmentation_transform():\n","  global _augmentation_transform\n","  if _augmentation_transform is None:\n","    _augmentation_transform = ImageDataGenerator(\n","      featurewise_center=False,\n","      featurewise_std_normalization=False,\n","      rotation_range=10,\n","      width_shift_range=0.1,\n","      height_shift_range=0.1,\n","      horizontal_flip=True,\n","      brightness_range=(0.9, 1.1),\n","      zoom_range=(0.85, 1.15),\n","      fill_mode='constant',\n","      cval=0.,\n","    )\n","  return _augmentation_transform\n","\n","def apply_augmentation(img):\n","    img = random_ratio_resize(img)\n","    img = get_augmentation_transform().random_transform(img)\n","    return img\n","\n","def _process_csv_file(file):\n","    with open(file, 'r') as fr:\n","        files = fr.readlines()\n","    return files\n","\n","\n","class BalanceCovidDataset(keras.utils.Sequence):\n","    'Generates data for Keras'\n","\n","    def __init__(\n","            self,\n","            data_dir,\n","            csv_file,\n","            is_training=True,\n","            batch_size=8,\n","            input_shape=(224, 224),\n","            num_channels=3,\n","            mapping={\n","                'negative': 0,\n","                'positive': 1,\n","            },\n","            shuffle=True,\n","            augmentation=apply_augmentation,\n","            covid_percent=0.5,\n","            class_weights=[1., 1.],\n","            top_percent=0.08\n","    ):\n","        'Initialization'\n","        self.datadir = data_dir\n","        self.dataset = _process_csv_file(csv_file)\n","        self.is_training = is_training\n","        self.batch_size = batch_size\n","        self.N = len(self.dataset)\n","        self.input_shape = input_shape\n","        self.num_channels = num_channels\n","        self.mapping = mapping\n","        self.shuffle = shuffle\n","        self.covid_percent = covid_percent\n","        self.class_weights = class_weights\n","        self.n = 0\n","        self.augmentation = augmentation\n","        self.top_percent = top_percent\n","\n","        datasets = {}\n","        for key in self.mapping.keys():\n","            datasets[key] = []\n","\n","        for l in self.dataset:\n","            if l.split()[-1] == 'sirm':\n","                datasets[l.split()[3]].append(l)\n","            else:\n","                datasets[l.split()[2]].append(l)\n","\n","        self.datasets = [\n","            datasets['negative'], datasets['positive']\n","        ]\n","        print(len(self.datasets[0]), len(self.datasets[1]))\n","\n","        self.on_epoch_end()\n","\n","    def __next__(self):\n","        # Get one batch of data\n","        batch_x, batch_y, weights = self.__getitem__(self.n)\n","        # Batch index\n","        self.n += 1\n","\n","        # If we have processed the entire dataset then\n","        if self.n >= self.__len__():\n","            self.on_epoch_end()\n","            self.n = 0\n","\n","        return batch_x, batch_y, weights\n","\n","    def __len__(self):\n","        return int(np.ceil(len(self.datasets[0]) / float(self.batch_size)))\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        if self.shuffle == True:\n","            for v in self.datasets:\n","                np.random.shuffle(v)\n","\n","    def __getitem__(self, idx):\n","        batch_x, batch_y = np.zeros(\n","            (self.batch_size, *self.input_shape,\n","             self.num_channels)), np.zeros(self.batch_size)\n","\n","        batch_files = self.datasets[0][idx * self.batch_size:(idx + 1) *\n","                                       self.batch_size]\n","\n","        # upsample covid cases\n","        covid_size = max(int(len(batch_files) * self.covid_percent), 1)\n","        covid_inds = np.random.choice(np.arange(len(batch_files)),\n","                                      size=covid_size,\n","                                      replace=False)\n","        covid_files = np.random.choice(self.datasets[1],\n","                                       size=covid_size,\n","                                       replace=False)\n","        for i in range(covid_size):\n","            batch_files[covid_inds[i]] = covid_files[i]\n","\n","        for i in range(len(batch_files)):\n","            sample = batch_files[i].split()\n","\n","            # Remove first item from sirm samples for proper indexing as a result of spacing in file name\n","            if sample[-1] == 'sirm':\n","                sample.pop(0)\n","\n","            if self.is_training:\n","                folder = 'train'\n","            else:\n","                folder = 'test'\n","\n","            x = process_image_file(os.path.join(self.datadir, folder, sample[1]),\n","                                   self.top_percent,\n","                                   self.input_shape[0])\n","\n","            if self.is_training and hasattr(self, 'augmentation'):\n","                x = self.augmentation(x)\n","\n","            x = x.astype('float32') / 255.0\n","            y = self.mapping[sample[2]]\n","\n","            batch_x[i] = x\n","            batch_y[i] = y\n","\n","        class_weights = self.class_weights\n","        weights = np.take(class_weights, batch_y.astype('int64'))\n","\n","        return batch_x, keras.utils.to_categorical(batch_y, num_classes=2), weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0eapeLSXRrSe"},"source":["def inference():\n","  # To remove TF Warnings\n","  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","  # example='/content/drive/MyDrive/covidnet/COVID-NET- CXR-2'\n","\n","  parser = argparse.ArgumentParser(description='COVID-Net Inference')\n","  parser.add_argument('--weightspath', default='/content/drive/MyDrive/covidnet/COVID-NET- CXR-2', type=str, help='Path to model files, defaults to \\'/content/drive/MyDrive/covidnet/COVID-NET- CXR-2\\'')\n","  parser.add_argument('--metaname', default='model.meta', type=str, help='Name of ckpt meta file')\n","  parser.add_argument('--ckptname', default='model', type=str, help='Name of model ckpts')\n","  parser.add_argument('--imagepath', default='assets/ex-covid.jpeg', type=str, help='Full path to image to be inferenced')\n","  parser.add_argument('--in_tensorname', default='input_1:0', type=str, help='Name of input tensor to graph')\n","  parser.add_argument('--out_tensorname', default='norm_dense_2/Softmax:0', type=str, help='Name of output tensor from graph')\n","  parser.add_argument('--input_size', default=480, type=int, help='Size of input (ex: if 480x480, --input_size 480)')\n","  parser.add_argument('--top_percent', default=0.08, type=float, help='Percent top crop from top of image')\n","\n","  args = parser.parse_args([])\n","\n","  # For COVID-19 positive/negative detection\n","  mapping = {'negative': 0, 'positive': 1}\n","  inv_mapping = {0: 'negative', 1: 'positive'}\n","  mapping_keys = list(mapping.keys())\n","\n","  sess = tf.Session()\n","  tf.get_default_graph()\n","  saver = tf.train.import_meta_graph(os.path.join(args.weightspath, args.metaname))\n","  saver.restore(sess, os.path.join(args.weightspath, args.ckptname))\n","\n","  graph = tf.get_default_graph()\n","\n","  image_tensor = graph.get_tensor_by_name(args.in_tensorname)\n","  pred_tensor = graph.get_tensor_by_name(args.out_tensorname)\n","\n","  x = process_image_file(args.imagepath, args.top_percent, args.input_size)\n","  x = x.astype('float32') / 255.0\n","  pred = sess.run(pred_tensor, feed_dict={image_tensor: np.expand_dims(x, axis=0)})\n","\n","  print('Prediction: {}'.format(inv_mapping[pred.argmax(axis=1)[0]]))\n","  print('Confidence')\n","  print(' '.join('{}: {:.3f}'.format(cls.capitalize(), pred[0][i]) for cls, i in mapping.items()))\n","  print('**DISCLAIMER**')\n","  print('Do not use this prediction for self-diagnosis. You should check with your local authorities for the latest advice on seeking medical assistance.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PJgW3yfriUe"},"source":["\n","def eval(sess, graph, testfile, testfolder, input_tensor, output_tensor, input_size, mapping):\n","    image_tensor = graph.get_tensor_by_name(input_tensor)\n","    pred_tensor = graph.get_tensor_by_name(output_tensor)\n","\n","    y_test = []\n","    pred = []\n","    for i in range(len(testfile)):\n","        line = testfile[i].split()\n","        x = process_image_file(os.path.join(testfolder, line[1]), 0.08, input_size)\n","        x = x.astype('float32') / 255.0\n","        y_test.append(mapping[line[2]])\n","        pred.append(np.array(sess.run(pred_tensor, feed_dict={image_tensor: np.expand_dims(x, axis=0)})).argmax(axis=1))\n","    y_test = np.array(y_test)\n","    pred = np.array(pred)\n","\n","    matrix = confusion_matrix(y_test, pred)\n","    matrix = matrix.astype('float')\n","    #cm_norm = matrix / matrix.sum(axis=1)[:, np.newaxis]\n","    print(matrix)\n","    #class_acc = np.array(cm_norm.diagonal())\n","    class_acc = [matrix[i,i]/np.sum(matrix[i,:]) if np.sum(matrix[i,:]) else 0 for i in range(len(matrix))]\n","\n","    print('Sens', ', '.join('{}: {:.3f}'.format(cls.capitalize(), class_acc[i]) for cls, i in mapping.items()))\n","    ppvs = [matrix[i,i]/np.sum(matrix[:,i]) if np.sum(matrix[:,i]) else 0 for i in range(len(matrix))]\n","    print('PPV', ', '.join('{}: {:.3f}'.format(cls.capitalize(), ppvs[i]) for cls, i in mapping.items()))\n","\n","def evaluate():\n","  # To remove TF Warnings\n","  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","  parser = argparse.ArgumentParser(description='COVID-Net Evaluation')\n","  parser.add_argument('--weightspath', default='/content/drive/MyDrive/covidnet/COVID-NET- CXR-2', type=str, help='Path to model files, defaults to \\'/content/drive/MyDrive/covidnet/COVID-NET- CXR-2\\'')\n","  parser.add_argument('--metaname', default='model.meta', type=str, help='Name of ckpt meta file')\n","  parser.add_argument('--ckptname', default='model', type=str, help='Name of model ckpts')\n","  parser.add_argument('--testfile', default='/content/drive/MyDrive/covidnet/labels/test_COVIDx8B.txt', type=str, help='Name of testfile')\n","  parser.add_argument('--testfolder', default='/content/drive/MyDrive/covidnet/data/test', type=str, help='Folder where test data is located')\n","  parser.add_argument('--in_tensorname', default='input_1:0', type=str, help='Name of input tensor to graph')\n","  parser.add_argument('--out_tensorname', default='norm_dense_2/Softmax:0', type=str, help='Name of output tensor from graph')\n","  parser.add_argument('--input_size', default=480, type=int, help='Size of input (ex: if 480x480, --input_size 480)')\n","\n","  args = parser.parse_args([])\n","\n","  sess = tf.Session()\n","  tf.get_default_graph()\n","  saver = tf.train.import_meta_graph(os.path.join(args.weightspath, args.metaname))\n","  saver.restore(sess, os.path.join(args.weightspath, args.ckptname))\n","\n","  graph = tf.get_default_graph()\n","\n","  file = open(args.testfile, 'r')\n","  testfile = file.readlines()\n","\n","  # For COVID-19 positive/negative detection\n","  mapping = {\n","      'negative': 0,\n","      'positive': 1,\n","  }\n","\n","  eval(sess, graph, testfile, args.testfolder, args.in_tensorname, args.out_tensorname, args.input_size, mapping)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iisdsP9orkoZ"},"source":["def train():\n","  # To remove TF Warnings\n","  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","  covid_percent = 0.16 # in the provided train_COVIDx8B.txt there are ~13800 negative and ~2160 positive samples\n","\n","  parser = argparse.ArgumentParser(description='COVID-Net Training Script')\n","  parser.add_argument('--epochs', default=15, type=int, help='Number of epochs')\n","  parser.add_argument('--lr', default=0.00005, type=float, help='Learning rate')\n","  parser.add_argument('--bs', default=32, type=int, help='Batch size')\n","  parser.add_argument('--weightspath', default='/content/drive/MyDrive/covidnet/COVID-Net CXR-2', type=str,\n","                      help='Path to model files, defaults to \\'/content/drive/MyDrive/covidnet/COVID-Net CXR-2\\'')\n","  parser.add_argument('--metaname', default='model.meta', type=str, help='Name of ckpt meta file')\n","  parser.add_argument('--ckptname', default='model', type=str, help='Name of model ckpts')\n","  parser.add_argument('--trainfile', default='/content/drive/MyDrive/covidnet/labels/train_COVIDx8B.txt', type=str, help='Path to train file')\n","  parser.add_argument('--testfile', default='/content/drive/MyDrive/covidnet/labels/test_COVIDx8B.txt', type=str, help='Path to test file')\n","  parser.add_argument('--name', default='training_checkpoints', type=str, help='Name of folder to store training checkpoints')\n","  parser.add_argument('--datadir', default='/content/drive/MyDrive/covidnet/data', type=str, help='Path to data folder')\n","  parser.add_argument('--covid_weight', default=1., type=float, help='Class weighting for covid')\n","  parser.add_argument('--covid_percent', default=covid_percent, type=float, help='Percentage of covid samples in batch')\n","  parser.add_argument('--input_size', default=480, type=int, help='Size of input (ex: if 480x480, --input_size 480)')\n","  parser.add_argument('--top_percent', default=0.08, type=float, help='Percent top crop from top of image')\n","  parser.add_argument('--in_tensorname', default='input_1:0', type=str, help='Name of input tensor to graph')\n","  parser.add_argument('--out_tensorname', default='norm_dense_2/Softmax:0', type=str,\n","                      help='Name of output tensor from graph')\n","  parser.add_argument('--logit_tensorname', default='norm_dense_2/MatMul:0', type=str,\n","                      help='Name of logit tensor for loss')\n","  parser.add_argument('--label_tensorname', default='norm_dense_1_target:0', type=str,\n","                      help='Name of label tensor for loss')\n","  parser.add_argument('--weights_tensorname', default='norm_dense_1_sample_weights:0', type=str,\n","                      help='Name of sample weights tensor for loss')\n","  parser.add_argument('--training_tensorname', default='keras_learning_phase:0', type=str,\n","                      help='Name of training placeholder tensor')\n","\n","\n","  args = parser.parse_args([])\n","\n","  # Parameters\n","  learning_rate = args.lr\n","  batch_size = args.bs\n","  display_step = 1\n","\n","  # output path\n","  outputPath = '/content/drive/MyDrive/covidnet/output/test/'\n","  runID = args.name + '-lr' + str(learning_rate)\n","  runPath = outputPath + runID\n","  pathlib.Path(runPath).mkdir(parents=True, exist_ok=True)\n","  print('Output: ' + runPath)\n","\n","  with open(args.trainfile) as f:\n","      trainfiles = f.readlines()\n","  with open(args.testfile) as f:\n","      testfiles = f.readlines()\n","\n","  # For COVID-19 positive/negative detection\n","  mapping = {\n","      'negative': 0,\n","      'positive': 1,\n","  }\n","  class_weights = [1., args.covid_weight]\n","\n","  generator = BalanceCovidDataset(data_dir=args.datadir,\n","                                  csv_file=args.trainfile,\n","                                  batch_size=batch_size,\n","                                  input_shape=(args.input_size, args.input_size),\n","                                  mapping=mapping,\n","                                  covid_percent=args.covid_percent,\n","                                  class_weights=class_weights,\n","                                  top_percent=args.top_percent)\n","  graph = tf.Graph()\n","  with tf.Session(graph=graph) as sess:\n","      saver = tf.train.import_meta_graph(os.path.join(args.weightspath, args.metaname))\n","\n","      #graph = tf.get_default_graph()\n","\n","      image_tensor = graph.get_tensor_by_name(args.in_tensorname)\n","      labels_tensor = graph.get_tensor_by_name(args.label_tensorname)\n","      sample_weights = graph.get_tensor_by_name(args.weights_tensorname)\n","      pred_tensor = graph.get_tensor_by_name(args.logit_tensorname)\n","      is_training = graph.get_tensor_by_name(args.training_tensorname)\n","      # loss expects unscaled logits since it performs a softmax on logits internally for efficiency\n","\n","      # Define loss and optimizer\n","      loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n","          logits=pred_tensor, labels=labels_tensor)*sample_weights)\n","      optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","      train_op = optimizer.minimize(loss_op)\n","\n","      # Initialize the variables\n","      init = tf.global_variables_initializer()\n","\n","      # Run the initializer\n","      sess.run(init)\n","\n","      # load weights\n","      saver.restore(sess, os.path.join(args.weightspath, args.ckptname))\n","      #saver.restore(sess, tf.train.latest_checkpoint(args.weightspath))\n","\n","      # save base model\n","      saver.save(sess, os.path.join(runPath, 'model'))\n","      print('Saved baseline checkpoint')\n","      print('Baseline eval:')\n","      eval(sess, graph, testfiles, os.path.join(args.datadir,'test'),\n","          args.in_tensorname, args.out_tensorname, args.input_size, mapping)\n","\n","      # Training cycle\n","      print('Training started')\n","      total_batch = len(generator)\n","      progbar = tf.keras.utils.Progbar(total_batch)\n","      for epoch in range(args.epochs):\n","          for i in range(total_batch):\n","              # Run optimization\n","              batch_x, batch_y, weights = next(generator)\n","              sess.run(train_op, feed_dict={image_tensor: batch_x,\n","                                            labels_tensor: batch_y,\n","                                            sample_weights: weights,\n","                                            is_training: True})\n","              progbar.update(i+1)\n","\n","          if epoch % display_step == 0:\n","              pred = sess.run(pred_tensor, feed_dict={image_tensor:batch_x})\n","              loss = sess.run(loss_op, feed_dict={pred_tensor: pred,\n","                                                  labels_tensor: batch_y,\n","                                                  sample_weights: weights})\n","              print(\"Epoch:\", '%04d' % (epoch + 1), \"Minibatch loss=\", \"{:.9f}\".format(loss))\n","              eval(sess, graph, testfiles, os.path.join(args.datadir,'test'),\n","                  args.in_tensorname, args.out_tensorname, args.input_size, mapping)\n","              saver.save(sess, os.path.join(runPath, 'model'), global_step=epoch+1, write_meta_graph=False)\n","              print('Saving checkpoint at epoch {}'.format(epoch + 1))\n","\n","\n","  print(\"Optimization Finished!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CojKdHQQrlwm","executionInfo":{"status":"ok","timestamp":1633106541044,"user_tz":-120,"elapsed":30517843,"user":{"displayName":"nameohne","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13436963316072193918"}},"outputId":"1cac3ba9-620f-4b03-edcf-938fce7b3513"},"source":["train()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Output: /content/drive/MyDrive/covidnet/output/test/training_checkpoints-lr5e-05\n","13794 2158\n","Saved baseline checkpoint\n","Baseline eval:\n","[[194.   6.]\n"," [  9. 191.]]\n","Sens Negative: 0.970, Positive: 0.955\n","PPV Negative: 0.956, Positive: 0.970\n","Training started\n","432/432 [==============================] - 9156s 21s/step\n","Epoch: 0001 Minibatch loss= 0.003375309\n","[[178.  22.]\n"," [  6. 194.]]\n","Sens Negative: 0.890, Positive: 0.970\n","PPV Negative: 0.967, Positive: 0.898\n","Saving checkpoint at epoch 1\n","432/432 [==============================] - 11939s 6s/step\n","Epoch: 0002 Minibatch loss= 0.000081834\n","[[176.  24.]\n"," [  5. 195.]]\n","Sens Negative: 0.880, Positive: 0.975\n","PPV Negative: 0.972, Positive: 0.890\n","Saving checkpoint at epoch 2\n","432/432 [==============================] - 13616s 4s/step\n","Epoch: 0003 Minibatch loss= 0.000971529\n","[[159.  41.]\n"," [  2. 198.]]\n","Sens Negative: 0.795, Positive: 0.990\n","PPV Negative: 0.988, Positive: 0.828\n","Saving checkpoint at epoch 3\n","432/432 [==============================] - 15070s 3s/step\n","Epoch: 0004 Minibatch loss= 0.000350011\n","[[168.  32.]\n"," [ 26. 174.]]\n","Sens Negative: 0.840, Positive: 0.870\n","PPV Negative: 0.866, Positive: 0.845\n","Saving checkpoint at epoch 4\n","432/432 [==============================] - 16481s 3s/step\n","Epoch: 0005 Minibatch loss= 0.170102030\n","[[ 24. 176.]\n"," [  0. 200.]]\n","Sens Negative: 0.120, Positive: 1.000\n","PPV Negative: 1.000, Positive: 0.532\n","Saving checkpoint at epoch 5\n","432/432 [==============================] - 17872s 3s/step\n","Epoch: 0006 Minibatch loss= 0.034812711\n","[[131.  69.]\n"," [ 15. 185.]]\n","Sens Negative: 0.655, Positive: 0.925\n","PPV Negative: 0.897, Positive: 0.728\n","Saving checkpoint at epoch 6\n","432/432 [==============================] - 19253s 3s/step\n","Epoch: 0007 Minibatch loss= 0.731338382\n","[[ 93. 107.]\n"," [  1. 199.]]\n","Sens Negative: 0.465, Positive: 0.995\n","PPV Negative: 0.989, Positive: 0.650\n","Saving checkpoint at epoch 7\n","432/432 [==============================] - 20617s 3s/step\n","Epoch: 0008 Minibatch loss= 0.000282859\n","[[121.  79.]\n"," [  4. 196.]]\n","Sens Negative: 0.605, Positive: 0.980\n","PPV Negative: 0.968, Positive: 0.713\n","Saving checkpoint at epoch 8\n","432/432 [==============================] - 21968s 3s/step\n","Epoch: 0009 Minibatch loss= 0.137671471\n","[[171.  29.]\n"," [ 32. 168.]]\n","Sens Negative: 0.855, Positive: 0.840\n","PPV Negative: 0.842, Positive: 0.853\n","Saving checkpoint at epoch 9\n","432/432 [==============================] - 23331s 3s/step\n","Epoch: 0010 Minibatch loss= 0.000235783\n","[[ 90. 110.]\n"," [  0. 200.]]\n","Sens Negative: 0.450, Positive: 1.000\n","PPV Negative: 1.000, Positive: 0.645\n","Saving checkpoint at epoch 10\n","432/432 [==============================] - 24687s 3s/step\n","Epoch: 0011 Minibatch loss= 0.189527079\n","[[ 90. 110.]\n"," [  2. 198.]]\n","Sens Negative: 0.450, Positive: 0.990\n","PPV Negative: 0.978, Positive: 0.643\n","Saving checkpoint at epoch 11\n","432/432 [==============================] - 26042s 3s/step\n","Epoch: 0012 Minibatch loss= 0.001387506\n","[[150.  50.]\n"," [ 15. 185.]]\n","Sens Negative: 0.750, Positive: 0.925\n","PPV Negative: 0.909, Positive: 0.787\n","Saving checkpoint at epoch 12\n","432/432 [==============================] - 27393s 3s/step\n","Epoch: 0013 Minibatch loss= 0.001042892\n","[[101.  99.]\n"," [  1. 199.]]\n","Sens Negative: 0.505, Positive: 0.995\n","PPV Negative: 0.990, Positive: 0.668\n","Saving checkpoint at epoch 13\n","432/432 [==============================] - 28742s 3s/step\n","Epoch: 0014 Minibatch loss= 0.284651756\n","[[ 80. 120.]\n"," [  3. 197.]]\n","Sens Negative: 0.400, Positive: 0.985\n","PPV Negative: 0.964, Positive: 0.621\n","Saving checkpoint at epoch 14\n","432/432 [==============================] - 30085s 3s/step\n","Epoch: 0015 Minibatch loss= 0.019565601\n","[[ 86. 114.]\n"," [  1. 199.]]\n","Sens Negative: 0.430, Positive: 0.995\n","PPV Negative: 0.989, Positive: 0.636\n","Saving checkpoint at epoch 15\n","Optimization Finished!\n"]}]},{"cell_type":"code","metadata":{"id":"JXWOhNne3-Q_"},"source":[""],"execution_count":null,"outputs":[]}]}