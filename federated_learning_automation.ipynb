{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "zwZJFe5-pCLV",
    "outputId": "34e05e6a-ae90-4a63-89e5-8d6ea1ca7996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in c:\\users\\donat\\anaconda3\\lib\\site-packages (0.1.20)\n",
      "Requirement already satisfied: kaggle in c:\\users\\donat\\anaconda3\\lib\\site-packages (from opendatasets) (1.5.12)\n",
      "Requirement already satisfied: click in c:\\users\\donat\\anaconda3\\lib\\site-packages (from opendatasets) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\donat\\anaconda3\\lib\\site-packages (from opendatasets) (4.59.0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\donat\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\donat\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.25.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\donat\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\donat\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\donat\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\donat\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.15.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\donat\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\donat\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\donat\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBD5W-SJWERa",
    "outputId": "1396852a-e233-49bb-80a1-f3fb16bf7c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct  2 16:41:50 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 472.12       Driver Version: 472.12       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P8     6W /  N/A |     96MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1296    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      3200    C+G   ...ician\\SamsungMagician.exe    N/A      |\n",
      "|    0   N/A  N/A      8356    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     10344    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     10580    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     10732    C+G   ...auncher\\PowerLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     14652    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     15400    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     15968    C+G   ...signal-desktop\\Signal.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TraicDeCpHii",
    "outputId": "b6cdd2b7-7c26-44a8-be17-7fbbe8ce7574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\chest-xray-covid19-pneumonia\" (use force=True to force download)\n",
      "Skipping, found downloaded files in \".\\novel-corona-virus-2019-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/prashant268/chest-xray-covid19-pneumonia\")\n",
    "od.download(\"https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WvAJ8eTnTRkP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JPFiGGjbhta_"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001 # 0.0001\n",
    "MAX_EPOCHS = 10\n",
    "TARGET_FOLDER = \"weights\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VW1RF4LvUUsG"
   },
   "source": [
    "Resize Images to 244, 244. By using to_tensor the images are already normalized between 0 and 1. \"The image object is an array of (244, 244, 3) should be flattened to be list (178, 608).\" What? wie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7Z_GY07pSzQT"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((244, 244))\n",
    "                                , transforms.ToTensor()]\n",
    "                               #, transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # find mean and std of dataset\n",
    "                              )\n",
    "\n",
    "test_set = datasets.ImageFolder('chest-xray-covid19-pneumonia/Data/test', transform=transform)\n",
    "\n",
    "train_set = dataset = datasets.ImageFolder('chest-xray-covid19-pneumonia/Data/train', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3Z9lep1yVWY3"
   },
   "outputs": [],
   "source": [
    "def label_preparation(labels):\n",
    "    labels = np.array(labels)\n",
    "    labels[labels > 0] = 1\n",
    "    return list(labels)\n",
    "\n",
    "def label_preparation_tensor(labels):\n",
    "    labels[labels > 0] = 1\n",
    "    return labels\n",
    "\n",
    "train_set.targets = label_preparation(train_set.targets)\n",
    "\n",
    "test_set.targets = label_preparation(test_set.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "icqqTTRN-ht6"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(result, labels):\n",
    "    result = torch.sigmoid(result).round()\n",
    "    \n",
    "    correct_results_sum = (result == labels).sum().float()\n",
    "    acc = correct_results_sum/labels.shape[0]\n",
    "    acc *= 100\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BNNFC2o-VWZC"
   },
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, loss):\n",
    "    accuracy = 0\n",
    "    for step, [images, labels] in enumerate(data_loader, 1):\n",
    "        labels = label_preparation_tensor(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        result = model(images)\n",
    "        targets = labels.float()\n",
    "        \n",
    "        # normal dataloader and custom dataloader return different sized targets\n",
    "        # normal has a shape of [32], while custom dataloader (correctly) uses [32, 1]\n",
    "        if len(targets.shape) == 1:\n",
    "            targets = targets.unsqueeze(1)\n",
    "\n",
    "        loss_value = loss(result.float(), targets)\n",
    "\n",
    "        # backpropagation\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "                                    \n",
    "        #if step % 10 == 0:\n",
    "        #    accuracy += calc_accuracy(result, targets)\n",
    "        #    print(f\"TRAINING - Step: {step}, loss: {loss_value}, rolling accuracy: {accuracy*10/step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nQ_ek0ayVWZC"
   },
   "outputs": [],
   "source": [
    "def test_fn(model, test_loader, loss):\n",
    "    with torch.no_grad():\n",
    "        loss_value = 0\n",
    "        accuracy = 0\n",
    "        for step, [images, labels] in enumerate(test_loader, 1):\n",
    "            labels = label_preparation_tensor(labels)\n",
    "\n",
    "            result = model(images)\n",
    "            targets = labels.detach().unsqueeze(1).float()\n",
    "\n",
    "            loss_value += loss(result.detach(), targets)\n",
    "            accuracy += calc_accuracy(result.detach(), targets)\n",
    "\n",
    "        loss_value /= step\n",
    "        accuracy /=  step\n",
    "        \n",
    "    #print(f\"TESTING - Loss: {loss_value}, Accuracy: {accuracy}\")\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWithTransform(torch.utils.data.Dataset):\n",
    "    dataset: torch.utils.data.Dataset\n",
    "    transform: torchvision.transforms.Compose\n",
    "\n",
    "    def __init__(self, dataset: torch.utils.data.Dataset, transform: torchvision.transforms.Compose) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "                      \n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.dataset[index]\n",
    "        x = self.transform(x)\n",
    "        \n",
    "        if isinstance(y, int):\n",
    "            y = torch.IntTensor([y])\n",
    "        elif isinstance(y, long):\n",
    "            y = torch.LongTensor([y])\n",
    "        elif isinstance(y, float):\n",
    "            y = torch.FloatTensor([y])\n",
    "        elif isinstance(y, double):\n",
    "            y = torch.DoubleTensor([y])\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable, Any\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "from __future__ import annotations\n",
    "\n",
    "class FederatedLearningTest:\n",
    "    __batch_size = 32\n",
    "    __shuffle_train_data = True\n",
    "    __num_workers = 0\n",
    "    __pin_memory = True\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_dataset: torch.utils.data.Dataset,\n",
    "        test_dataset: torch.utils.data.Dataset,\n",
    "        train_epoch_fn: Callable[[torch.nn.Module, torch.utils.data.DataLoader, torch.optim.Optimizer, torch.nn.modules.loss._Loss], None], \n",
    "        test_fn: Callable[[torch.nn.Module, torch.utils.data.DataLoader, torch.nn.modules.loss._Loss], Any],\n",
    "        use_gpu: bool,\n",
    "        epochs_to_train: int\n",
    "    ):\n",
    "        self.__model = model\n",
    "        self.__train_dataset = train_dataset\n",
    "        self.__test_dataset = test_dataset\n",
    "        self.__train_epoch_fn = train_epoch_fn\n",
    "        self.__test_fn = test_fn\n",
    "        self.__use_gpu = use_gpu\n",
    "        self.__epochs_to_train = epochs_to_train\n",
    "\n",
    "    def __update_client_model(self, federated_model, client_model):\n",
    "        client_model.load_state_dict(federated_model.state_dict(), True)\n",
    "        return client_model\n",
    "\n",
    "    def __federated_average(self, federated_model, client_models):\n",
    "        average_weights = OrderedDict()\n",
    "\n",
    "        number_of_clients = len(client_models)\n",
    "        for client_model in client_models:\n",
    "            for key, value in client_model.state_dict().items():\n",
    "                if key in average_weights:\n",
    "                    average_weights[key] += (1./number_of_clients) * value.clone()\n",
    "                else:\n",
    "                    average_weights[key] = (1./number_of_clients) * value.clone()\n",
    "\n",
    "\n",
    "        federated_model.load_state_dict(average_weights, True)\n",
    "        return federated_model\n",
    "        \n",
    "    # TODO future: currently only works with image data, make it more generic\n",
    "    # TODO future(?): add some debug prints?\n",
    "    def __prepare_train_data(\n",
    "        self,\n",
    "        train_dataset: torch.utils.data.Dataset,\n",
    "        no_of_clients: int,\n",
    "        augment_data: bool,\n",
    "        full_data_on_each_client: bool,\n",
    "        batch_size: int, shuffle: bool, num_workers: int, pin_memory: bool\n",
    "    ) -> List[torch.utils.data.DataLoader]:\n",
    "    \n",
    "        if augment_data:\n",
    "            # flip, then rotate and shift\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomAffine(degrees=30, translate=(0.1, 0.1)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor()])\n",
    "\n",
    "        data_loaders = []\n",
    "        if full_data_on_each_client:\n",
    "            data_loaders = [\n",
    "                torch.utils.data.DataLoader(\n",
    "                    DatasetWithTransform(train_dataset, transform),\n",
    "                    batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory\n",
    "                )\n",
    "            for _ in range(no_of_clients)]\n",
    "        else:\n",
    "            chunk_size_train = len(train_dataset) // no_of_clients\n",
    "            indices_train = np.random.permutation(np.arange(chunk_size_train * no_of_clients)) \n",
    "\n",
    "            for idx in range(no_of_clients):\n",
    "                data_loader_train = torch.utils.data.Subset(train_dataset, indices_train[idx*chunk_size_train:(idx+1)*chunk_size_train])\n",
    "                data_loaders += [\n",
    "                    torch.utils.data.DataLoader(\n",
    "                        DatasetWithTransform(data_loader_train, transform),\n",
    "                        batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "        return data_loaders\n",
    "    \n",
    "    def __get_device(self):\n",
    "        if not self.__use_gpu:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"Using CPU\")\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(\"Using GPU\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"You requested to use GPU, but CUDA is not available. Using CPU instead\")\n",
    "        \n",
    "        return device\n",
    "    \n",
    "    def __wrap_data_loader(self, loader, device):\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            yield x, y\n",
    "    \n",
    "    def set_batch_size(self, batch_size: int) -> FederatedLearningTest:\n",
    "        self.__batch_size = batch_size\n",
    "        return self\n",
    "    \n",
    "    def set_shuffle_train_data(self, shuffle_train_data: bool) -> FederatedLearningTest:\n",
    "        self.__shuffle_train_data = shuffle_train_data\n",
    "        return self\n",
    "    \n",
    "    def set_dataloader_workers(self, num_workers: int) -> FederatedLearningTest:\n",
    "        self.__num_workers = num_workers\n",
    "        return self\n",
    "    \n",
    "    def set_pin_training_memory(self, pin_memory: bool) -> FederatedLearningTest:\n",
    "        self.__pin_memory = pin_memory\n",
    "        return self\n",
    "    \n",
    "    def compare(\n",
    "        self,\n",
    "        augment_data: bool,\n",
    "        full_data_on_each_client: bool,\n",
    "        no_of_clients: int,\n",
    "        construct_optimizer_fn: Callable[[torch.nn.Module], torch.optim.Optimizer],\n",
    "        construct_loss_fn: Callable[[], torch.nn.modules.loss._Loss],\n",
    "        test_after_each_epoch: bool = False\n",
    "    ):\n",
    "        device = self.__get_device()\n",
    "        if device.type == \"cuda\": \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print(\"Training sequential model\")\n",
    "        sequential_model = copy.deepcopy(self.__model).to(device)\n",
    "        \n",
    "        sequential_optimizer = construct_optimizer_fn(sequential_model)\n",
    "        sequential_loss = construct_loss_fn().to(device)\n",
    "        \n",
    "        sequential_train_loader = torch.utils.data.DataLoader(\n",
    "            self.__train_dataset,\n",
    "            batch_size=self.__batch_size,\n",
    "            shuffle=self.__shuffle_train_data,\n",
    "            num_workers=self.__num_workers,\n",
    "            pin_memory=self.__pin_memory\n",
    "        )\n",
    "        \n",
    "        sequential_test_loader = torch.utils.data.DataLoader(\n",
    "            self.__test_dataset,\n",
    "            batch_size=self.__batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.__num_workers\n",
    "        )\n",
    "        \n",
    "        for idx in range(self.__epochs_to_train):\n",
    "            print(f\"Epoch: {idx+1}\")\n",
    "            sequential_model.train()\n",
    "            sequential_train_loader_device = self.__wrap_data_loader(sequential_train_loader, device)\n",
    "            self.__train_epoch_fn(sequential_model, sequential_train_loader_device, sequential_optimizer, sequential_loss)\n",
    "            sequential_train_loader_device = None\n",
    "            \n",
    "            if test_after_each_epoch:\n",
    "                sequential_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    print(f\"Test results for epoch {idx+1}:\")\n",
    "                    sequential_test_loader_device = self.__wrap_data_loader(sequential_test_loader, device)\n",
    "                    print(self.__test_fn(sequential_model, sequential_test_loader_device, sequential_loss))\n",
    "                    sequential_test_loader_device = None\n",
    "        \n",
    "        print(\"Sequential training complete, testing ...\")\n",
    "        sequential_model.eval()\n",
    "        with torch.no_grad():\n",
    "            sequential_test_loader = self.__wrap_data_loader(sequential_test_loader, device)\n",
    "            sequential_test_results = self.__test_fn(sequential_model, sequential_test_loader, sequential_loss)\n",
    "        \n",
    "        sequential_model.to(\"cpu\")\n",
    "        sequential_train_loader = None\n",
    "        sequential_test_loader = None\n",
    "        sequential_loss = None\n",
    "        sequential_optimizer = None\n",
    "        sequential_model = None\n",
    "        \n",
    "        print(\"Test results for sequential model:\")\n",
    "        print(sequential_test_results)\n",
    "        \n",
    "        if device.type == \"cuda\": \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        print(\"\\n++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        \n",
    "        print(\"Training federated model(s)\")\n",
    "        federated_model = copy.deepcopy(self.__model)\n",
    "        client_models = [copy.deepcopy(self.__model) for _ in range(no_of_clients)]\n",
    "        \n",
    "        federated_loss = construct_loss_fn().to(device)\n",
    "        \n",
    "        federated_training_dataloaders = self.__prepare_train_data(\n",
    "            self.__train_dataset,\n",
    "            no_of_clients,\n",
    "            augment_data,\n",
    "            full_data_on_each_client,\n",
    "            self.__batch_size,\n",
    "            self.__shuffle_train_data,\n",
    "            self.__num_workers,\n",
    "            self.__pin_memory\n",
    "        )\n",
    "        \n",
    "        federated_test_loader = torch.utils.data.DataLoader(\n",
    "            self.__test_dataset,\n",
    "            batch_size=self.__batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.__num_workers\n",
    "        )\n",
    "\n",
    "        for idx in range(self.__epochs_to_train):\n",
    "            for client_idx in range (no_of_clients):\n",
    "                print(f\"Epoch: {idx+1}, client {client_idx+1}\")\n",
    "                \n",
    "                client_model = client_models[client_idx].to(device)\n",
    "                \n",
    "                client_model = self.__update_client_model(federated_model, client_model)\n",
    "                client_optimizer = construct_optimizer_fn(client_model)\n",
    "                \n",
    "                client_training_loader_device = self.__wrap_data_loader(federated_training_dataloaders[client_idx], device)\n",
    "                self.__train_epoch_fn(client_model, client_training_loader_device, client_optimizer, federated_loss)\n",
    "                client_training_loader_device = None\n",
    "\n",
    "                if device.type == \"cuda\": \n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                client_model.to(\"cpu\")\n",
    "                client_optimizer = None\n",
    "            \n",
    "            federated_model = self.__federated_average(federated_model, client_models)\n",
    "\n",
    "            if test_after_each_epoch:\n",
    "                federated_model.to(device)\n",
    "                federated_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    print(f\"Test results for epoch {idx+1}:\")\n",
    "                    federated_test_loader_device = self.__wrap_data_loader(federated_test_loader, device)\n",
    "                    print(self.__test_fn(federated_model, federated_test_loader_device, federated_loss))\n",
    "                    federated_test_loader_device = None\n",
    "                    \n",
    "                federated_model.to(\"cpu\")\n",
    "        \n",
    "        \n",
    "        print(\"Federated training complete, testing ...\")\n",
    "        federated_model.to(device)\n",
    "        federated_model.eval()\n",
    "        with torch.no_grad():\n",
    "            federated_test_loader = self.__wrap_data_loader(federated_test_loader, device)\n",
    "            federated_test_results = self.__test_fn(federated_model, federated_test_loader, federated_loss)\n",
    "        \n",
    "        federated_model.to(\"cpu\")\n",
    "        federated_training_dataloaders = None\n",
    "        federated_test_loader = None\n",
    "        federated_loss = None\n",
    "        client_models = None\n",
    "        federated_model = None\n",
    "        \n",
    "        print(\"Test results for federated model:\")\n",
    "        print(federated_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Training sequential model\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Donat\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Sequential training complete, testing ...\n",
      "Test results for sequential model:\n",
      "97.86585235595703\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "Training federated model(s)\n",
      "Epoch: 1, client 1\n",
      "Epoch: 1, client 2\n",
      "Epoch: 1, client 3\n",
      "Epoch: 1, client 4\n",
      "Epoch: 2, client 1\n",
      "Epoch: 2, client 2\n",
      "Epoch: 2, client 3\n",
      "Epoch: 2, client 4\n",
      "Epoch: 3, client 1\n",
      "Epoch: 3, client 2\n",
      "Epoch: 3, client 3\n",
      "Epoch: 3, client 4\n",
      "Epoch: 4, client 1\n",
      "Epoch: 4, client 2\n",
      "Epoch: 4, client 3\n",
      "Epoch: 4, client 4\n",
      "Epoch: 5, client 1\n",
      "Epoch: 5, client 2\n",
      "Epoch: 5, client 3\n",
      "Epoch: 5, client 4\n",
      "Federated training complete, testing ...\n",
      "Test results for federated model:\n",
      "96.03658294677734\n"
     ]
    }
   ],
   "source": [
    "number_of_clients = 4\n",
    "\n",
    "def construct_optimizer(model):\n",
    "    return torch.optim.Adam(model.parameters())\n",
    "\n",
    "def construct_loss():\n",
    "    # use pos weights because of unbalanced data set\n",
    "    return torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([1./10])) # binary crossentropy\n",
    "\n",
    "\n",
    "model_to_test = torchvision.models.resnet18(pretrained=False, num_classes=1)\n",
    "\n",
    "federated_test = FederatedLearningTest(\n",
    "    model_to_test, train_set, test_set,\n",
    "    train_epoch_fn=train_fn, \n",
    "    test_fn=test_fn,\n",
    "    use_gpu=True, epochs_to_train=5\n",
    ").set_batch_size(32).set_shuffle_train_data(True).set_dataloader_workers(0).set_pin_training_memory(True)\n",
    "\n",
    "federated_test.compare(\n",
    "    augment_data=False,\n",
    "    full_data_on_each_client=False,\n",
    "    no_of_clients=number_of_clients,\n",
    "    construct_optimizer_fn = construct_optimizer,\n",
    "    construct_loss_fn = construct_loss,\n",
    "    test_after_each_epoch = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "federated_learning_with_save.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
