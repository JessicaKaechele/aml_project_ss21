{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von federated.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ya5ZEuZpSnE",
        "outputId": "b38228b4-bcc4-40fd-dc67-4b97a1db088b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPFiGGjbhta_"
      },
      "source": [
        "LEARNING_RATE = 0.14\n",
        "EPOCHS = 100\n",
        "TARGET_FOLDER = \"weights\"\n",
        "K_FOLDS = 5"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvAJ8eTnTRkP"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW1RF4LvUUsG"
      },
      "source": [
        "Resize Images to 244, 244. By using to_tensor the images are already normalized between 0 and 1. \"The image object is an array of (244, 244, 3) should be flattened to be list (178, 608).\" What? wie?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z_GY07pSzQT"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((256, 256)),\n",
        "                                 transforms.ToTensor()])\n",
        "\n",
        "data_set = datasets.ImageFolder('/content/drive/MyDrive/data_aml/X-Ray Image DataSet', transform=transform)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAi62OkRTZfV"
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(data_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWhXD92ZRzNP",
        "outputId": "2cb0c3ee-5a97-4085-d71e-03df79fd0739"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Current device: {device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qihhc_PTgVr"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        for_pad = lambda s: s if s > 2 else 3\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=(for_pad(kernel_size) - 1)//2, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True) \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class TripleConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(TripleConvBlock, self).__init__()\n",
        "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
        "        self.conv_block_2 = ConvBlock(out_channels, in_channels, kernel_size=1)  \n",
        "        self.conv_block_3 = ConvBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_block_1(x)\n",
        "        out = self.conv_block_2(out)\n",
        "        out = self.conv_block_3(out)\n",
        "        return out\n",
        "\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model2, self).__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "        ConvBlock(3, 8),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        ConvBlock(8, 16),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(16, 32),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(32,64),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(64,128),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(128,256),\n",
        "        ConvBlock(256, 128, kernel_size=1),\n",
        "        ConvBlock(128, 256),\n",
        "        nn.Conv2d(256, 2, 3, padding=(3-1)//2, stride=1), # Ich bekomme es nicht hin, dass das identisch ist \n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(2),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(338,2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)\n",
        "\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model3, self).__init__()\n",
        "        self.seq = nn.Sequential(\n",
        "        ConvBlock(3, 8),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        ConvBlock(8, 16),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(16, 32),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(32,64),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(64,128),\n",
        "        nn.MaxPool2d(2, stride=2),\n",
        "        TripleConvBlock(128,256),\n",
        "        ConvBlock(256, 128, kernel_size=1),\n",
        "        ConvBlock(128, 256),\n",
        "        nn.Conv2d(256, 3, 3, padding=(3-1)//2, stride=1), # Ich bekomme es nicht hin, dass das identisch ist \n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(3),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(507,3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.seq(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAItZORR0N0H",
        "outputId": "eecca098-6ebf-4bb9-af8b-72030e6de3b7"
      },
      "source": [
        "from torchsummary import summary\n",
        "model = Model3()\n",
        "summary(model, (3, 256, 256))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 256, 256]             216\n",
            "       BatchNorm2d-2          [-1, 8, 256, 256]              16\n",
            "         LeakyReLU-3          [-1, 8, 256, 256]               0\n",
            "         ConvBlock-4          [-1, 8, 256, 256]               0\n",
            "         MaxPool2d-5          [-1, 8, 128, 128]               0\n",
            "            Conv2d-6         [-1, 16, 128, 128]           1,152\n",
            "       BatchNorm2d-7         [-1, 16, 128, 128]              32\n",
            "         LeakyReLU-8         [-1, 16, 128, 128]               0\n",
            "         ConvBlock-9         [-1, 16, 128, 128]               0\n",
            "        MaxPool2d-10           [-1, 16, 64, 64]               0\n",
            "           Conv2d-11           [-1, 32, 64, 64]           4,608\n",
            "      BatchNorm2d-12           [-1, 32, 64, 64]              64\n",
            "        LeakyReLU-13           [-1, 32, 64, 64]               0\n",
            "        ConvBlock-14           [-1, 32, 64, 64]               0\n",
            "           Conv2d-15           [-1, 16, 66, 66]             512\n",
            "      BatchNorm2d-16           [-1, 16, 66, 66]              32\n",
            "        LeakyReLU-17           [-1, 16, 66, 66]               0\n",
            "        ConvBlock-18           [-1, 16, 66, 66]               0\n",
            "           Conv2d-19           [-1, 32, 66, 66]           4,608\n",
            "      BatchNorm2d-20           [-1, 32, 66, 66]              64\n",
            "        LeakyReLU-21           [-1, 32, 66, 66]               0\n",
            "        ConvBlock-22           [-1, 32, 66, 66]               0\n",
            "  TripleConvBlock-23           [-1, 32, 66, 66]               0\n",
            "        MaxPool2d-24           [-1, 32, 33, 33]               0\n",
            "           Conv2d-25           [-1, 64, 33, 33]          18,432\n",
            "      BatchNorm2d-26           [-1, 64, 33, 33]             128\n",
            "        LeakyReLU-27           [-1, 64, 33, 33]               0\n",
            "        ConvBlock-28           [-1, 64, 33, 33]               0\n",
            "           Conv2d-29           [-1, 32, 35, 35]           2,048\n",
            "      BatchNorm2d-30           [-1, 32, 35, 35]              64\n",
            "        LeakyReLU-31           [-1, 32, 35, 35]               0\n",
            "        ConvBlock-32           [-1, 32, 35, 35]               0\n",
            "           Conv2d-33           [-1, 64, 35, 35]          18,432\n",
            "      BatchNorm2d-34           [-1, 64, 35, 35]             128\n",
            "        LeakyReLU-35           [-1, 64, 35, 35]               0\n",
            "        ConvBlock-36           [-1, 64, 35, 35]               0\n",
            "  TripleConvBlock-37           [-1, 64, 35, 35]               0\n",
            "        MaxPool2d-38           [-1, 64, 17, 17]               0\n",
            "           Conv2d-39          [-1, 128, 17, 17]          73,728\n",
            "      BatchNorm2d-40          [-1, 128, 17, 17]             256\n",
            "        LeakyReLU-41          [-1, 128, 17, 17]               0\n",
            "        ConvBlock-42          [-1, 128, 17, 17]               0\n",
            "           Conv2d-43           [-1, 64, 19, 19]           8,192\n",
            "      BatchNorm2d-44           [-1, 64, 19, 19]             128\n",
            "        LeakyReLU-45           [-1, 64, 19, 19]               0\n",
            "        ConvBlock-46           [-1, 64, 19, 19]               0\n",
            "           Conv2d-47          [-1, 128, 19, 19]          73,728\n",
            "      BatchNorm2d-48          [-1, 128, 19, 19]             256\n",
            "        LeakyReLU-49          [-1, 128, 19, 19]               0\n",
            "        ConvBlock-50          [-1, 128, 19, 19]               0\n",
            "  TripleConvBlock-51          [-1, 128, 19, 19]               0\n",
            "        MaxPool2d-52            [-1, 128, 9, 9]               0\n",
            "           Conv2d-53            [-1, 256, 9, 9]         294,912\n",
            "      BatchNorm2d-54            [-1, 256, 9, 9]             512\n",
            "        LeakyReLU-55            [-1, 256, 9, 9]               0\n",
            "        ConvBlock-56            [-1, 256, 9, 9]               0\n",
            "           Conv2d-57          [-1, 128, 11, 11]          32,768\n",
            "      BatchNorm2d-58          [-1, 128, 11, 11]             256\n",
            "        LeakyReLU-59          [-1, 128, 11, 11]               0\n",
            "        ConvBlock-60          [-1, 128, 11, 11]               0\n",
            "           Conv2d-61          [-1, 256, 11, 11]         294,912\n",
            "      BatchNorm2d-62          [-1, 256, 11, 11]             512\n",
            "        LeakyReLU-63          [-1, 256, 11, 11]               0\n",
            "        ConvBlock-64          [-1, 256, 11, 11]               0\n",
            "  TripleConvBlock-65          [-1, 256, 11, 11]               0\n",
            "           Conv2d-66          [-1, 128, 13, 13]          32,768\n",
            "      BatchNorm2d-67          [-1, 128, 13, 13]             256\n",
            "        LeakyReLU-68          [-1, 128, 13, 13]               0\n",
            "        ConvBlock-69          [-1, 128, 13, 13]               0\n",
            "           Conv2d-70          [-1, 256, 13, 13]         294,912\n",
            "      BatchNorm2d-71          [-1, 256, 13, 13]             512\n",
            "        LeakyReLU-72          [-1, 256, 13, 13]               0\n",
            "        ConvBlock-73          [-1, 256, 13, 13]               0\n",
            "           Conv2d-74            [-1, 3, 13, 13]           6,915\n",
            "             ReLU-75            [-1, 3, 13, 13]               0\n",
            "      BatchNorm2d-76            [-1, 3, 13, 13]               6\n",
            "          Flatten-77                  [-1, 507]               0\n",
            "           Linear-78                    [-1, 3]           1,524\n",
            "================================================================\n",
            "Total params: 1,167,589\n",
            "Trainable params: 1,167,589\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 51.62\n",
            "Params size (MB): 4.45\n",
            "Estimated Total Size (MB): 56.83\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Me-0EHR_md"
      },
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    \"\"\"\n",
        "    model -- neural net\n",
        "    data_loader -- dataloader for train images\n",
        "    optimizer -- optimizer\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "    \n",
        "    for step, [images, labels] in enumerate(data_loader,0):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        result = model(images)\n",
        "        loss = criterion(result, labels)\n",
        "                \n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                                    \n",
        "        if step%10 == 0:\n",
        "            print(f\"Step: {step}, loss: {loss}\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icqqTTRN-ht6"
      },
      "source": [
        "def calc_accuracy(result, labels):\n",
        "    result = torch.round(result)\n",
        "    probs = torch.softmax(result, dim=1)\n",
        "\n",
        "    correct_results_sum = (probs.argmax(dim=1) == labels).sum().float()\n",
        "    acc = correct_results_sum/labels.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk2CR_whWTxw"
      },
      "source": [
        "def test(model, test_loader, epoch):\n",
        "    \"\"\"    \n",
        "    model -- neural net \n",
        "    test_loader -- dataloader of test images\n",
        "    epoch -- current epoch\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    for step, [images, labels] in enumerate(test_loader,0):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        result = model(images)\n",
        "        loss += criterion(result.detach(), labels.detach())\n",
        "        accuracy += calc_accuracy(result.detach(), labels.detach())\n",
        "    loss /= step\n",
        "    accuracy /=  step\n",
        "  \n",
        "    print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kls3WJQpRmwf"
      },
      "source": [
        "kfold = KFold(n_splits=K_FOLDS, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "jzfyMxdBVoB1",
        "outputId": "e70135f9-37f1-4c86-bbc1-ea654f2018e4"
      },
      "source": [
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
        "    \n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "    \n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "                      data_set, \n",
        "                      batch_size=32, sampler=train_subsampler)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "                      data_set,\n",
        "                      batch_size=32, sampler=test_subsampler)\n",
        "    \n",
        "    model = Model3()\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "    \n",
        "    for epoch in range(0, EPOCHS):\n",
        "\n",
        "      train(model, train_loader, optimizer)\n",
        "      \n",
        "      torch.save(model.state_dict(), f'{TARGET_FOLDER}/fold_{fold}_epoch_{epoch}.ckpt')\n",
        "\n",
        "      test(model, test_loader, epoch)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "Step: 0, loss: 1.3826792240142822\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a2ed44c63fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{TARGET_FOLDER}/fold_{fold}_epoch_{epoch}.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-21d6a1605f62>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc9Z1kAKniiG"
      },
      "source": [
        "# Federated\n",
        "https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines/\n",
        "\n",
        "Neuste Version (0.3.x) hat kein TorchHook -> Lösung finden?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NUJv9PNBuANj",
        "outputId": "73d2c80e-4049-4b7f-8e6f-9456892a2416"
      },
      "source": [
        "!pip install syft==0.2.9 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting syft==0.2.9\n",
            "  Downloading syft-0.2.9-py3-none-any.whl (433 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 276 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 286 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 327 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 348 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 368 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 389 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 399 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 430 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 433 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill~=0.3.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.3.4)\n",
            "Collecting websocket-client~=0.57.0\n",
            "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |████████████████████████████████| 200 kB 64.1 MB/s \n",
            "\u001b[?25hCollecting lz4~=3.0.2\n",
            "  Downloading lz4-3.0.2-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (7.1.2)\n",
            "Collecting shaloop==0.2.1-alpha.11\n",
            "  Downloading shaloop-0.2.1_alpha.11-py3-none-manylinux1_x86_64.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 68.1 MB/s \n",
            "\u001b[?25hCollecting openmined.threepio==0.2.0\n",
            "  Downloading openmined.threepio-0.2.0.tar.gz (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting RestrictedPython~=5.0\n",
            "  Downloading RestrictedPython-5.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting requests-toolbelt==0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting requests~=2.22.0\n",
            "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.1)\n",
            "Collecting aiortc==0.9.28\n",
            "  Downloading aiortc-0.9.28-cp37-cp37m-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 61.1 MB/s \n",
            "\u001b[?25hCollecting psutil==5.7.0\n",
            "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 73.0 MB/s \n",
            "\u001b[?25hCollecting syft-proto~=0.5.2\n",
            "  Downloading syft_proto-0.5.3-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting tornado==4.5.3\n",
            "  Downloading tornado-4.5.3.tar.gz (484 kB)\n",
            "\u001b[K     |████████████████████████████████| 484 kB 34.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.0.2)\n",
            "Collecting torchvision~=0.5.0\n",
            "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 62.5 MB/s \n",
            "\u001b[?25hCollecting numpy~=1.18.1\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting tblib~=1.6.0\n",
            "  Downloading tblib-1.6.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting importlib-resources~=1.5.0\n",
            "  Downloading importlib_resources-1.5.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting torch~=1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 7.9 kB/s \n",
            "\u001b[?25hCollecting flask-socketio~=4.2.1\n",
            "  Downloading Flask_SocketIO-4.2.1-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.1.4)\n",
            "Collecting phe~=1.4.0\n",
            "  Downloading phe-1.4.0.tar.gz (35 kB)\n",
            "Collecting notebook==5.7.8\n",
            "  Downloading notebook-5.7.8-py2.py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 57.6 MB/s \n",
            "\u001b[?25hCollecting websockets~=8.1.0\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting aioice<0.7.0,>=0.6.17\n",
            "  Downloading aioice-0.6.18-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (1.14.6)\n",
            "Collecting crc32c\n",
            "  Downloading crc32c-2.2.post0-cp37-cp37m-manylinux2010_x86_64.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting av<9.0.0,>=8.0.0\n",
            "  Downloading av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2 MB 33 kB/s \n",
            "\u001b[?25hCollecting pylibsrtp>=0.5.6\n",
            "  Downloading pylibsrtp-0.6.8-cp37-cp37m-manylinux2010_x86_64.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting pyee>=6.0.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Collecting cryptography>=2.2\n",
            "  Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_24_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 83.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (1.8.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.3)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (22.2.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.12.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.11.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.3.5)\n",
            "Requirement already satisfied: pycparser>=2 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (2.20)\n",
            "Collecting netifaces\n",
            "  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.1.0)\n",
            "Collecting python-socketio>=4.3.0\n",
            "  Downloading python_socketio-5.4.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.4 in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook==5.7.8->syft==0.2.9) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (1.15.0)\n",
            "Collecting python-engineio>=4.1.0\n",
            "  Downloading python_engineio-4.2.1-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 544 kB/s \n",
            "\u001b[?25hCollecting bidict>=0.21.0\n",
            "  Downloading bidict-0.21.3-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2021.5.30)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from syft-proto~=0.5.2->syft==0.2.9) (3.17.3)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook==5.7.8->syft==0.2.9) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->importlib-resources~=1.5.0->syft==0.2.9) (3.7.4.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook==5.7.8->syft==0.2.9) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.2.5)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook==5.7.8->syft==0.2.9) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (2.4.7)\n",
            "Building wheels for collected packages: openmined.threepio, psutil, tornado, phe\n",
            "  Building wheel for openmined.threepio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openmined.threepio: filename=openmined.threepio-0.2.0-py3-none-any.whl size=80095 sha256=5b403856094a3601e468fc16f31acf1a5008072a7428bbbdc74d6d7f9ee7c3ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/3d/ce/4ca4386006e622cb87d5116e5e65026ec021d3cf906a9b3d5d\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276477 sha256=66dc4d62b3ca1550f5c330ec1997d5d6739fb9f3b9725459ad9eda3b1e5f59f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/e7/50/aee9cc966163d74430f13f208171dee22f11efa4a4a826661c\n",
            "  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434058 sha256=29d5b229a7150e4c11cefd8189276d289f1af101ac98a827a5ba433e34738efb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/45/43/36ec7a893e16c1212a6b1505ded0a2d73cf8e863a0227c8e04\n",
            "  Building wheel for phe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37362 sha256=9a8dc95fb840fd009a1b2953b43564c42db31c2b85553e590415e72f5e3c1e07\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/ac/9b/b07a04fe6bb1418ab4ee06d6652757aef848b80363c4dac507\n",
            "Successfully built openmined.threepio psutil tornado phe\n",
            "Installing collected packages: tornado, python-engineio, netifaces, idna, bidict, torch, requests, python-socketio, pylibsrtp, pyee, numpy, cryptography, crc32c, av, aioice, websockets, websocket-client, torchvision, tblib, syft-proto, shaloop, RestrictedPython, requests-toolbelt, psutil, phe, openmined.threepio, notebook, lz4, importlib-resources, flask-socketio, aiortc, syft\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "  Attempting uninstall: tblib\n",
            "    Found existing installation: tblib 1.7.0\n",
            "    Uninstalling tblib-1.7.0:\n",
            "      Successfully uninstalled tblib-1.7.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: notebook\n",
            "    Found existing installation: notebook 5.3.1\n",
            "    Uninstalling notebook-5.3.1:\n",
            "      Successfully uninstalled notebook-5.3.1\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.2.2\n",
            "    Uninstalling importlib-resources-5.2.2:\n",
            "      Successfully uninstalled importlib-resources-5.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.4.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.18.5 which is incompatible.\n",
            "google-colab 1.0.0 requires notebook~=5.3.0; python_version >= \"3.0\", but you have notebook 5.7.8 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 4.5.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires tornado>=5.1, but you have tornado 4.5.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed RestrictedPython-5.1 aioice-0.6.18 aiortc-0.9.28 av-8.0.3 bidict-0.21.3 crc32c-2.2.post0 cryptography-3.4.8 flask-socketio-4.2.1 idna-2.8 importlib-resources-1.5.0 lz4-3.0.2 netifaces-0.11.0 notebook-5.7.8 numpy-1.18.5 openmined.threepio-0.2.0 phe-1.4.0 psutil-5.7.0 pyee-8.2.2 pylibsrtp-0.6.8 python-engineio-4.2.1 python-socketio-5.4.0 requests-2.22.0 requests-toolbelt-0.9.1 shaloop-0.2.1a11 syft-0.2.9 syft-proto-0.5.3 tblib-1.6.0 torch-1.4.0 torchvision-0.5.0 tornado-4.5.3 websocket-client-0.57.0 websockets-8.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "psutil",
                  "torch",
                  "torchvision",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQFhBN-Fnlgp"
      },
      "source": [
        "import syft as sy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOoNGgmunvJA"
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "nr_of_instances = 2\n",
        "instances = []\n",
        "for i in range(nr_of_instances):\n",
        "  instances.append(sy.VirtualWorker(hook, id=str(i)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "066yRC19oVN8"
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 100\n",
        "        self.lr = 0.14\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "args = Arguments()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5-tPO3rCpDqB"
      },
      "source": [
        "federated_data_loader = sy.FederatedDataLoader(data_set.federate(instances),\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13oQqXfHrDX5"
      },
      "source": [
        "def train(args, model, train_loader, optims, epoch):\n",
        "    model.train()\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer = optims.get_optim(data.location.id)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.get()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get()\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR2YMmTLs49U",
        "outputId": "79a8e582-2fd9-4f9e-f9f0-50ffe4b7dc3a"
      },
      "source": [
        "\n",
        "from syft.federated.floptimizer import Optims\n",
        "\n",
        "\n",
        "\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(data_set)):\n",
        "    \n",
        "    print(f'FOLD {fold}')\n",
        "    print('--------------------------------')\n",
        "    \n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "                      data_set, \n",
        "                      batch_size=32, sampler=train_subsampler)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "                      data_set,\n",
        "                      batch_size=32, sampler=test_subsampler)\n",
        "    \n",
        "    federated_model = Model3()\n",
        "    \n",
        "    federated_optimizer = Optims(list(range(nr_of_instances)), optim=torch.optim.Adam(params=federated_model.parameters(),lr=args.lr))\n",
        "    \n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "\n",
        "      train(args, federated_model, federated_data_loader, federated_optimizer, epoch)\n",
        "\n",
        "      if (args.save_model):\n",
        "        torch.save(federated_model.state_dict(), f'{TARGET_FOLDER}/federated_fold_{fold}_epoch_{epoch}.ckpt')\n",
        "\n",
        "      test(federated_model, test_loader, epoch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD 0\n",
            "--------------------------------\n",
            "Train Epoch: 1 [0/1152 (0%)]\tLoss: 1.585826\n",
            "Train Epoch: 1 [320/1152 (28%)]\tLoss: 0.462757\n",
            "Train Epoch: 1 [640/1152 (56%)]\tLoss: 1.332489\n",
            "Train Epoch: 1 [960/1152 (83%)]\tLoss: 4.794581\n",
            "Loss: 4139.73193359375, Accuracy: 46.71428680419922\n",
            "Train Epoch: 2 [0/1152 (0%)]\tLoss: 37.647072\n",
            "Train Epoch: 2 [320/1152 (28%)]\tLoss: 8.295449\n",
            "Train Epoch: 2 [640/1152 (56%)]\tLoss: 45.125534\n",
            "Train Epoch: 2 [960/1152 (83%)]\tLoss: 1.111818\n",
            "Loss: 63.211883544921875, Accuracy: 46.57143020629883\n",
            "Train Epoch: 3 [0/1152 (0%)]\tLoss: 67.502190\n",
            "Train Epoch: 3 [320/1152 (28%)]\tLoss: 12.189524\n",
            "Train Epoch: 3 [640/1152 (56%)]\tLoss: 192.262924\n",
            "Train Epoch: 3 [960/1152 (83%)]\tLoss: 14.047342\n",
            "Loss: 133.20265197753906, Accuracy: 55.42856979370117\n",
            "Train Epoch: 4 [0/1152 (0%)]\tLoss: 222.663315\n",
            "Train Epoch: 4 [320/1152 (28%)]\tLoss: 2.321252\n",
            "Train Epoch: 4 [640/1152 (56%)]\tLoss: 495.440765\n",
            "Train Epoch: 4 [960/1152 (83%)]\tLoss: 25.120312\n",
            "Loss: 56.788597106933594, Accuracy: 43.28571319580078\n",
            "Train Epoch: 5 [0/1152 (0%)]\tLoss: 112.544632\n",
            "Train Epoch: 5 [320/1152 (28%)]\tLoss: 24.043621\n",
            "Train Epoch: 5 [640/1152 (56%)]\tLoss: 316.955627\n",
            "Train Epoch: 5 [960/1152 (83%)]\tLoss: 41.878334\n",
            "Loss: 89.62078857421875, Accuracy: 50.57143020629883\n",
            "Train Epoch: 6 [0/1152 (0%)]\tLoss: 136.682083\n",
            "Train Epoch: 6 [320/1152 (28%)]\tLoss: 18.859186\n",
            "Train Epoch: 6 [640/1152 (56%)]\tLoss: 520.706299\n",
            "Train Epoch: 6 [960/1152 (83%)]\tLoss: 2.590223\n",
            "Loss: 6.1189351081848145, Accuracy: 55.14285659790039\n",
            "Train Epoch: 7 [0/1152 (0%)]\tLoss: 9.572345\n",
            "Train Epoch: 7 [320/1152 (28%)]\tLoss: 0.787318\n",
            "Train Epoch: 7 [640/1152 (56%)]\tLoss: 74.749985\n",
            "Train Epoch: 7 [960/1152 (83%)]\tLoss: 17.683916\n",
            "Loss: 111.30406188964844, Accuracy: 50.71428680419922\n",
            "Train Epoch: 8 [0/1152 (0%)]\tLoss: 187.709381\n",
            "Train Epoch: 8 [320/1152 (28%)]\tLoss: 69.922203\n",
            "Train Epoch: 8 [640/1152 (56%)]\tLoss: 25.995041\n",
            "Train Epoch: 8 [960/1152 (83%)]\tLoss: 4.207253\n",
            "Loss: 5.850311756134033, Accuracy: 55.14285659790039\n",
            "Train Epoch: 9 [0/1152 (0%)]\tLoss: 8.615386\n",
            "Train Epoch: 9 [320/1152 (28%)]\tLoss: 0.705657\n",
            "Train Epoch: 9 [640/1152 (56%)]\tLoss: 47.263397\n",
            "Train Epoch: 9 [960/1152 (83%)]\tLoss: 34.420902\n",
            "Loss: 94.27783966064453, Accuracy: 50.85714340209961\n",
            "Train Epoch: 10 [0/1152 (0%)]\tLoss: 157.640594\n",
            "Train Epoch: 10 [320/1152 (28%)]\tLoss: 24.936161\n",
            "Train Epoch: 10 [640/1152 (56%)]\tLoss: 1.752387\n",
            "Train Epoch: 10 [960/1152 (83%)]\tLoss: 3.643264\n",
            "Loss: 13.2047119140625, Accuracy: 55.0\n",
            "Train Epoch: 11 [0/1152 (0%)]\tLoss: 21.284195\n",
            "Train Epoch: 11 [320/1152 (28%)]\tLoss: 11.718110\n",
            "Train Epoch: 11 [640/1152 (56%)]\tLoss: 1.006308\n",
            "Train Epoch: 11 [960/1152 (83%)]\tLoss: 18.437233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLC89DQ2rKQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}