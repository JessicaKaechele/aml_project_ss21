{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwZJFe5-pCLV",
        "outputId": "5b270b81-a9e7-43d9-cc42-378c0fed3740"
      },
      "source": [
        "!pip install opendatasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.62.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.5.30)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpd3iU1El1ZT"
      },
      "source": [
        "import opendatasets as od\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TraicDeCpHii",
        "outputId": "ec940e7b-0a35-4c28-9a85-98f7d7b3f6c0"
      },
      "source": [
        "od.download(\"https://www.kaggle.com/prashant268/chest-xray-covid19-pneumonia\")\n",
        "# od.download(\"https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: jessicakaechele\n",
            "Your Kaggle Key: ··········\n",
            "Downloading chest-xray-covid19-pneumonia.zip to ./chest-xray-covid19-pneumonia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.06G/2.06G [00:23<00:00, 95.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPFiGGjbhta_"
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 2\n",
        "TARGET_FOLDER = \"weights\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvAJ8eTnTRkP"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW1RF4LvUUsG"
      },
      "source": [
        "Resize Images to 244, 244. By using to_tensor the images are already normalized between 0 and 1. \"The image object is an array of (244, 244, 3) should be flattened to be list (178, 608).\" What? wie?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z_GY07pSzQT"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((244, 244)),\n",
        "                                 transforms.ToTensor()])\n",
        "\n",
        "test_set = datasets.ImageFolder('chest-xray-covid19-pneumonia/Data/test', transform=transform)\n",
        "train_set = dataset = datasets.ImageFolder('chest-xray-covid19-pneumonia/Data/train', transform=transform)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9HuvLqC5rMB"
      },
      "source": [
        "train_set.targets = torch.tensor(train_set.targets)\n",
        "train_set.targets[train_set.targets > 0] = 1\n",
        "\n",
        "test_set.targets = torch.tensor(test_set.targets)\n",
        "test_set.targets[test_set.targets > 0] = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LYb6MycBPtB"
      },
      "source": [
        "The dataset is extremely unbalanced. Maybe sth which should be handled?  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4budf2sh5XQ-"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87o-9Dz5WX-8"
      },
      "source": [
        "Creating Sample Data Dictionary\n",
        "After flattening the data dictionary instance was created for each image sample to represent the image data (features) and its label.\n",
        "Creating Samples and labels Tensors keras Objects\n",
        "To build keras the dataset, the keras tensor object should be built for features and keras tensor object for labels.\n",
        "Create Keras Tensor Dataset\n",
        "Create keras dataset by using from_tensor_slices API.\n",
        "\n",
        "nicht nötig?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCqEJbYaWH8A"
      },
      "source": [
        "Data Repetition\n",
        "Data repeated to simulate the number of clients.\n",
        "Data Shuffling\n",
        "Data shuffled to avoid obtaining the same results.\n",
        "Data Batching\n",
        "Data grouped into batches to enhance their performance.\n",
        "\n",
        "vielleicht nicht nötig mit syft? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAi62OkRTZfV"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHO2CHSsWvi2"
      },
      "source": [
        "Data Mapping\n",
        "ndarray dataset flattend to 1 darray dataset.\n",
        "Data Prefetching\n",
        "Data cached in memory for better performance.\n",
        "\n",
        "wie?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVxct9thFVz2"
      },
      "source": [
        "In Paper aus References haben sie unter anderen ResNet18 benutzt: https://arxiv.org/pdf/2007.05592.pdf\n",
        "\n",
        "Deshalb würde ich das probieren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWhXD92ZRzNP",
        "outputId": "b473ca2e-2e15-4480-dab7-4fd210df225a"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Current device: {device}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qihhc_PTgVr",
        "outputId": "f0cbdde8-51b8-4b39-b9a9-b12b0b5ad7c9"
      },
      "source": [
        "import torchvision\n",
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "model.fc = torch.nn.Linear(512, 1)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAItZORR0N0H"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgvIilEB9nYk"
      },
      "source": [
        "\n",
        "def transform_labels(labels):\n",
        "  labels[labels>0] = 1\n",
        "  return labels"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Me-0EHR_md"
      },
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    \"\"\"\n",
        "    model -- neural net\n",
        "    data_loader -- dataloader for train images\n",
        "    optimizer -- optimizer\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    criterion = torch.nn.BCELoss().to(device)\n",
        "    \n",
        "    for step, [images, labels] in enumerate(data_loader,0):\n",
        "        images = images.to(device)\n",
        "        labels = transform_labels(labels.to(device))\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        result = torch.nn.functional.softmax(model(images))\n",
        "      \n",
        "        loss = criterion(result, labels.unsqueeze(1).type(torch.FloatTensor))\n",
        "                \n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "                                    \n",
        "        if step%10 == 0:\n",
        "            print(f\"Step: {step}, loss: {loss}\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icqqTTRN-ht6"
      },
      "source": [
        "def calc_accuracy(result, labels):\n",
        "    result = torch.round(result)\n",
        "\n",
        "    correct_results_sum = (result == labels).sum().float()\n",
        "    acc = correct_results_sum/labels.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk2CR_whWTxw"
      },
      "source": [
        "def test(model, test_loader, epoch):\n",
        "    \"\"\"    \n",
        "    model -- neural net \n",
        "    test_loader -- dataloader of test images\n",
        "    epoch -- current epoch\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "    for step, [images, labels] in enumerate(test_loader,0):\n",
        "        images = images.to(device)\n",
        "        labels = transform_labels(labels.to(device))\n",
        "        result = torch.nn.functional.softmax(model(images))\n",
        "        loss += criterion(result.detach(), labels.detach())\n",
        "        accuracy += calc_accuracy(result.detach(), labels.detach())\n",
        "    loss /= step\n",
        "    accuracy /=  step\n",
        "  \n",
        "    print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "jzfyMxdBVoB1",
        "outputId": "c3a6aff3-d0a6-4a92-fd67-8d72310e227d"
      },
      "source": [
        "# initialize optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "# start training\n",
        "for epoch in range(EPOCHS):\n",
        "    train(model, train_loader, optimizer)\n",
        "    \n",
        "    # save interim weights\n",
        "    torch.save(model.state_dict(), f'{TARGET_FOLDER}/epoch_{epoch}.ckpt')\n",
        "\n",
        "    test(model, test_loader, epoch)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0, loss: 9.375\n",
            "Step: 10, loss: 9.375\n",
            "Step: 20, loss: 9.375\n",
            "Step: 30, loss: 6.25\n",
            "Step: 40, loss: 9.375\n",
            "Step: 50, loss: 9.375\n",
            "Step: 60, loss: 18.75\n",
            "Step: 70, loss: 9.375\n",
            "Step: 80, loss: 6.25\n",
            "Step: 90, loss: 12.5\n",
            "Step: 100, loss: 12.5\n",
            "Step: 110, loss: 12.5\n",
            "Step: 120, loss: 0.0\n",
            "Step: 130, loss: 9.375\n",
            "Step: 140, loss: 15.625\n",
            "Step: 150, loss: 3.125\n",
            "Step: 160, loss: 8.333333015441895\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-48fda31dfa26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# save interim weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{TARGET_FOLDER}/epoch_{epoch}.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights/epoch_0.ckpt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc9Z1kAKniiG"
      },
      "source": [
        "# Federated\n",
        "https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines/\n",
        "\n",
        "Neuste Version (0.3.x) hat kein TorchHook -> Lösung finden?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUJv9PNBuANj",
        "outputId": "aae7edfe-b9ce-4cdb-8e6a-10f7a5c3847b"
      },
      "source": [
        "!pip install syft==0.2.9 "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: syft==0.2.9 in /usr/local/lib/python3.7/dist-packages (0.2.9)\n",
            "Requirement already satisfied: websockets~=8.1.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (8.1)\n",
            "Requirement already satisfied: numpy~=1.18.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.18.5)\n",
            "Requirement already satisfied: tblib~=1.6.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.6.0)\n",
            "Requirement already satisfied: lz4~=3.0.2 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (3.0.2)\n",
            "Requirement already satisfied: Flask~=1.1.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.1.4)\n",
            "Requirement already satisfied: torch~=1.4.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.0)\n",
            "Requirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (4.5.3)\n",
            "Requirement already satisfied: requests-toolbelt==0.9.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.9.1)\n",
            "Requirement already satisfied: shaloop==0.2.1-alpha.11 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.2.1a11)\n",
            "Requirement already satisfied: requests~=2.22.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (2.22.0)\n",
            "Requirement already satisfied: flask-socketio~=4.2.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (4.2.1)\n",
            "Requirement already satisfied: psutil==5.7.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (5.7.0)\n",
            "Requirement already satisfied: openmined.threepio==0.2.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.2.0)\n",
            "Requirement already satisfied: phe~=1.4.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.0)\n",
            "Requirement already satisfied: notebook==5.7.8 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (5.7.8)\n",
            "Requirement already satisfied: msgpack~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.0.2)\n",
            "Requirement already satisfied: RestrictedPython~=5.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (5.1)\n",
            "Requirement already satisfied: dill~=0.3.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.3.4)\n",
            "Requirement already satisfied: syft-proto~=0.5.2 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.5.3)\n",
            "Requirement already satisfied: scipy~=1.4.1 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.4.1)\n",
            "Requirement already satisfied: importlib-resources~=1.5.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (1.5.0)\n",
            "Requirement already satisfied: aiortc==0.9.28 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.9.28)\n",
            "Requirement already satisfied: torchvision~=0.5.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.5.0)\n",
            "Requirement already satisfied: Pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (7.1.2)\n",
            "Requirement already satisfied: websocket-client~=0.57.0 in /usr/local/lib/python3.7/dist-packages (from syft==0.2.9) (0.57.0)\n",
            "Requirement already satisfied: av<9.0.0,>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (8.0.3)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (1.14.6)\n",
            "Requirement already satisfied: pyee>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (8.2.2)\n",
            "Requirement already satisfied: aioice<0.7.0,>=0.6.17 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (0.6.18)\n",
            "Requirement already satisfied: cryptography>=2.2 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (3.4.8)\n",
            "Requirement already satisfied: pylibsrtp>=0.5.6 in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (0.6.8)\n",
            "Requirement already satisfied: crc32c in /usr/local/lib/python3.7/dist-packages (from aiortc==0.9.28->syft==0.2.9) (2.2.post0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.7.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (2.11.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (4.10.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (22.2.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.11.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.11.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.0.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.3.5)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.6.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook==5.7.8->syft==0.2.9) (5.1.3)\n",
            "Requirement already satisfied: pycparser>=2 in /usr/local/lib/python3.7/dist-packages (from shaloop==0.2.1-alpha.11->syft==0.2.9) (2.20)\n",
            "Requirement already satisfied: netifaces in /usr/local/lib/python3.7/dist-packages (from aioice<0.7.0,>=0.6.17->aiortc==0.9.28->syft==0.2.9) (0.11.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1.1->syft==0.2.9) (1.0.1)\n",
            "Requirement already satisfied: python-socketio>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from flask-socketio~=4.2.1->syft==0.2.9) (5.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.4 in /usr/local/lib/python3.7/dist-packages (from importlib-resources~=1.5.0->syft==0.2.9) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook==5.7.8->syft==0.2.9) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=5.2.0->notebook==5.7.8->syft==0.2.9) (1.15.0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft==0.2.9) (0.21.3)\n",
            "Requirement already satisfied: python-engineio>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft==0.2.9) (4.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (2021.5.30)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.22.0->syft==0.2.9) (3.0.4)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from syft-proto~=0.5.2->syft==0.2.9) (3.17.3)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook==5.7.8->syft==0.2.9) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->importlib-resources~=1.5.0->syft==0.2.9) (3.7.4.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->notebook==5.7.8->syft==0.2.9) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook==5.7.8->syft==0.2.9) (0.2.5)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (4.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook==5.7.8->syft==0.2.9) (0.8.4)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook==5.7.8->syft==0.2.9) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook==5.7.8->syft==0.2.9) (2.4.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQFhBN-Fnlgp"
      },
      "source": [
        "import syft as sy\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOoNGgmunvJA",
        "outputId": "7ad58512-c9e4-45ef-a5ce-3edc0d423973"
      },
      "source": [
        "hook = sy.TorchHook(torch)\n",
        "nr_of_instances = 2\n",
        "instances = []\n",
        "for i in range(nr_of_instances):\n",
        "  instances.append(sy.VirtualWorker(hook, id=str(i)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Torch was already hooked... skipping hooking process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "066yRC19oVN8"
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 32\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.0001\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "args = Arguments()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-tPO3rCpDqB"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "\n",
        "federated_train_loader = sy.FederatedDataLoader(train_set.federate(instances),\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,\n",
        "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13oQqXfHrDX5"
      },
      "source": [
        "def train(args, model, train_loader, optims, epoch):\n",
        "    model.train()\n",
        "\n",
        "    criterion = torch.nn.BCELoss().to(device)\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location)\n",
        "        data, target = data.to(device), transform_labels(target.to(device))\n",
        "\n",
        "        optimizer = optims.get_optim(data.location.id)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = torch.nn.functional.softmax(model(data))\n",
        "\n",
        "        loss = criterion(output, target.unsqueeze(1).type(torch.FloatTensor))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.get()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get()\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "hR2YMmTLs49U",
        "outputId": "f2c51ce1-3579-46de-9458-7b03e73c8cec"
      },
      "source": [
        "federated_model = torchvision.models.resnet18(pretrained=False)\n",
        "federated_model.fc = torch.nn.Linear(512, 1)\n",
        "\n",
        "from syft.federated.floptimizer import Optims\n",
        "federated_optimizer = Optims(list(range(nr_of_instances)), optim=torch.optim.Adam(params=federated_model.parameters(),lr=args.lr))\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, federated_model, federated_train_loader, federated_optimizer, epoch)\n",
        "\n",
        "    if (args.save_model):\n",
        "      torch.save(federated_model.state_dict(), f'{TARGET_FOLDER}/epoch_{epoch}.ckpt')\n",
        "\n",
        "    test(federated_model, test_loader, epoch)\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/syft/frameworks/torch/tensors/interpreters/native.py:414: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  response = command_method(*args_, **kwargs_)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/5152 (0%)]\tLoss: 3.453878\n",
            "Train Epoch: 1 [320/5152 (6%)]\tLoss: 3.453878\n",
            "Train Epoch: 1 [640/5152 (12%)]\tLoss: 3.453878\n",
            "Train Epoch: 1 [960/5152 (19%)]\tLoss: 7.771225\n",
            "Train Epoch: 1 [1280/5152 (25%)]\tLoss: 4.317347\n",
            "Train Epoch: 1 [1600/5152 (31%)]\tLoss: 2.590408\n",
            "Train Epoch: 1 [1920/5152 (37%)]\tLoss: 7.771225\n",
            "Train Epoch: 1 [2240/5152 (43%)]\tLoss: 3.453878\n",
            "Train Epoch: 1 [2560/5152 (50%)]\tLoss: -6.907755\n",
            "Train Epoch: 1 [2880/5152 (56%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [3200/5152 (62%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [3520/5152 (68%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [3840/5152 (75%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [4160/5152 (81%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [4480/5152 (87%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [4800/5152 (93%)]\tLoss: 0.000000\n",
            "Train Epoch: 1 [5120/5152 (99%)]\tLoss: 0.000000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-57e245db1a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederated_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{TARGET_FOLDER}/epoch_{epoch}.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederated_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLC89DQ2rKQe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
