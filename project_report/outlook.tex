\section{Conclusion and Outlook}
The last section will give a brief conclusion of results that we achieved and explore some ideas and concepts that can be used to further improve our automated federation test in the future.  

\subsection{Conclusion}
We were able to replicate results of all but one of the papers that we selected and successfully adopted their approaches to utilize the concept of federated learning. In almost all cases the federated version achieved similar results to the centralized one, indicating that federated learning can indeed be used in COVID-19 research to preserve data privacy of sensitive medical data. The adaption was successful in CNN as well as GNN architectures, showing that not only one type of network can be used with federated learning. This could enable research projects with multiple entities, for example government health organizations, working together on one big machine learning model, which seemed to be impossible due to privacy concerns in the past.
We did not deploy our federation models on different hardware and thus completely ignored the communication usually necessary for aggregating local models. In addition, we used Federated Averaging, the most basic aggregation technique in federated learning, instead of a more sophisticated approach like weighted Federated Averaging or algorithms built on top of it like \enquote{FedProx}\cite{fed_prox} or \enquote{FedSplit}\cite{fed_split}. Nevertheless, our results still show that federated learning has a huge potential for COVID-19 and other research and that further research with it should be done.

Further, we developed a python class which can be used to quickly and with relative ease test how federated learning performs with a given model and training methodology before having to commit to building a custom solution or integrate a complex framework into existing code for that purpose. This will hopefully make the barrier-of-entrance to more development with federated learning easier and result in more projects using it in the future.

\subsection{Outlook}
Even though our automated federation test works quite well on the models we tested it with we cannot guarantee that it works on any other. It should be tested with a lot more models and datasets to get a higher confidence in its ability to indeed work with most image based PyTorch models.  
Apart from more testing there is also a lot of room for potential improvement in other areas. First, the current data augmentations for increasing the data available on each client needs to be more configurable and make more augmentations available to fit more scenarios. Taking this a step further, we could also support non-image data and their transformations. For being able to test even more real-world scenarios, it would also be of value to be able to split and distribute the data in different, non-random ways (e.g. give some clients most of the data of one class and other clients most of the data of other classes).
By supporting PyTorch models we, at least in theory, also support models of frameworks that are based on PyTorch. While this is a big portion of all machine learning models, it is by no means all of them. Support for Tensorflow and its respective dataset format is almost a must if we want to make quick testing of federated learning available to a large portion of the machine learning community.
